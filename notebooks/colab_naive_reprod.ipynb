{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow -y"
      ],
      "metadata": {
        "id": "zeGxEpUS88hU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6713d169-d355-4295-db5b-29ebc7cdcf6c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 1.14.0\n",
            "Uninstalling tensorflow-1.14.0:\n",
            "  Successfully uninstalled tensorflow-1.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.7 -y\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
        "!sudo update-alternatives --config python3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBpNTgL7Cs_E",
        "outputId": "fdf432fa-10bc-400c-bca6-5a6683b7e884"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r            \rHit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Connected to cloud.r-project.org (52.85.151.8)] [Connecting to r2u.stat.ill\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "\r0% [Waiting for headers] [Connected to cloud.r-project.org (52.85.151.8)] [Conn\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\r0% [Connected to cloud.r-project.org (52.85.151.8)] [Connected to r2u.stat.illi\r                                                                               \rHit:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Connected to develope\r                                                                               \rHit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3.7 is already the newest version (3.7.17-1+jammy1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
            "There are 3 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                 Priority   Status\n",
            "------------------------------------------------------------\n",
            "  0            /usr/bin/python3.11   2         auto mode\n",
            "  1            /usr/bin/python3.10   1         manual mode\n",
            "  2            /usr/bin/python3.11   2         manual mode\n",
            "* 3            /usr/bin/python3.7    1         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install python3.7-distutils\n",
        "!sudo apt-get install python3-pip -y\n",
        "!python3 -m pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYKm0c6YEdr4",
        "outputId": "9c8a0aaa-b247-4de0-d408-331746508945"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3.7-distutils is already the newest version (3.7.17-1+jammy1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-pip is already the newest version (22.0.2+dfsg-1ubuntu0.5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (24.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install virtualenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptFcykX_08ld",
        "outputId": "47f6139a-3183-488f-c7a8-8302e25e0004"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: virtualenv in /usr/local/lib/python3.7/dist-packages (20.26.6)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (0.3.9)\n",
            "Requirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (3.12.2)\n",
            "Requirement already satisfied: importlib-metadata>=6.6 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (6.7.0)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (4.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata>=6.6->virtualenv) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=6.6->virtualenv) (4.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!virtualenv -p python3.7 py37_env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR7Jdbzh1Asy",
        "outputId": "b9a50a71-d495-4442-acca-fb2451bba80f"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created virtual environment CPython3.7.17.final.0-64 in 224ms\n",
            "  creator CPython3Posix(dest=/content/liquid_time_constant_networks/experiments_with_ltcs/py37_env, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==24.0, setuptools==68.0.0, wheel==0.42.0\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source py37_env/bin/activate"
      ],
      "metadata": {
        "id": "ZcTuACE71E7V"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEsN2Fm7VeKX",
        "outputId": "aeb1bdcb-dab0-4ac6-96e6-42afb492766a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'liquid_time_constant_networks'...\n",
            "remote: Enumerating objects: 116, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 116 (delta 18), reused 9 (delta 9), pack-reused 89 (from 1)\u001b[K\n",
            "Receiving objects: 100% (116/116), 3.95 MiB | 15.28 MiB/s, done.\n",
            "Resolving deltas: 100% (38/38), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tnmtvv/liquid_time_constant_networks.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/liquid_time_constant_networks/experiments_with_ltcs"
      ],
      "metadata": {
        "id": "0J09FmOYWMSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee84519d-17fb-4fa7-c43d-37ae3552ac55"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/liquid_time_constant_networks/experiments_with_ltcs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cc2TPBmXBVM",
        "outputId": "18dd6d3c-7eac-4a16-d3ca-1154961cbc5a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cheetah.py      \u001b[0m\u001b[01;34mdata\u001b[0m/                 gesture.py  ltc_model.py  ozone.py   power.py   traffic.py\n",
            "ctrnn_model.py  download_datasets.sh  har.py      occupancy.py  person.py  smnist.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x download_datasets.sh"
      ],
      "metadata": {
        "id": "nxb5_vYVXMaK"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!source download_datasets.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL8sqKpXpGWe",
        "outputId": "d9b2f2aa-66a1-4051-8356-2831160c008c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-19 12:07:49--  https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘UCI HAR Dataset.zip’\n",
            "\n",
            "UCI HAR Dataset.zip     [         <=>        ]  58.17M  31.6MB/s    in 1.8s    \n",
            "\n",
            "2025-02-19 12:07:52 (31.6 MB/s) - ‘UCI HAR Dataset.zip’ saved [60999314]\n",
            "\n",
            "Archive:  UCI HAR Dataset.zip\n",
            "   creating: data/har/UCI HAR Dataset/\n",
            "  inflating: data/har/UCI HAR Dataset/.DS_Store  \n",
            "   creating: data/har/__MACOSX/\n",
            "   creating: data/har/__MACOSX/UCI HAR Dataset/\n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/._.DS_Store  \n",
            "  inflating: data/har/UCI HAR Dataset/activity_labels.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/._activity_labels.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/features.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/._features.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/features_info.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/._features_info.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/README.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/._README.txt  \n",
            "   creating: data/har/UCI HAR Dataset/test/\n",
            "   creating: data/har/UCI HAR Dataset/test/Inertial Signals/\n",
            "  inflating: data/har/UCI HAR Dataset/test/Inertial Signals/body_acc_x_test.txt  \n",
            "   creating: data/har/__MACOSX/UCI HAR Dataset/test/\n",
            "   creating: data/har/__MACOSX/UCI HAR Dataset/test/Inertial Signals/\n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_acc_x_test.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/test/Inertial Signals/body_acc_y_test.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_acc_y_test.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/test/Inertial Signals/body_acc_z_test.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_acc_z_test.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/test/Inertial Signals/body_gyro_x_test.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_gyro_x_test.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/test/Inertial Signals/body_gyro_y_test.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_gyro_y_test.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/test/Inertial Signals/body_gyro_z_test.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_gyro_z_test.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/test/Inertial Signals/total_acc_x_test.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/test/Inertial Signals/._total_acc_x_test.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/test/Inertial Signals/total_acc_y_test.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/test/Inertial Signals/._total_acc_y_test.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/test/Inertial Signals/total_acc_z_test.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/test/Inertial Signals/._total_acc_z_test.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/test/._Inertial Signals  \n",
            "  inflating: data/har/UCI HAR Dataset/test/subject_test.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/test/._subject_test.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/test/X_test.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/test/._X_test.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/test/y_test.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/test/._y_test.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/._test  \n",
            "   creating: data/har/UCI HAR Dataset/train/\n",
            "   creating: data/har/UCI HAR Dataset/train/Inertial Signals/\n",
            "  inflating: data/har/UCI HAR Dataset/train/Inertial Signals/body_acc_x_train.txt  \n",
            "   creating: data/har/__MACOSX/UCI HAR Dataset/train/\n",
            "   creating: data/har/__MACOSX/UCI HAR Dataset/train/Inertial Signals/\n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_acc_x_train.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/train/Inertial Signals/body_acc_y_train.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_acc_y_train.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/train/Inertial Signals/body_acc_z_train.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_acc_z_train.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/train/Inertial Signals/body_gyro_x_train.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_gyro_x_train.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/train/Inertial Signals/body_gyro_y_train.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_gyro_y_train.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/train/Inertial Signals/body_gyro_z_train.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_gyro_z_train.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/train/Inertial Signals/total_acc_x_train.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/train/Inertial Signals/._total_acc_x_train.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/train/Inertial Signals/total_acc_y_train.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/train/Inertial Signals/._total_acc_y_train.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/train/Inertial Signals/total_acc_z_train.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/train/Inertial Signals/._total_acc_z_train.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/train/._Inertial Signals  \n",
            "  inflating: data/har/UCI HAR Dataset/train/subject_train.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/train/._subject_train.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/train/X_train.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/train/._X_train.txt  \n",
            "  inflating: data/har/UCI HAR Dataset/train/y_train.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/train/._y_train.txt  \n",
            "  inflating: data/har/__MACOSX/UCI HAR Dataset/._train  \n",
            "  inflating: data/har/__MACOSX/._UCI HAR Dataset  \n",
            "--2025-02-19 12:07:54--  https://archive.ics.uci.edu/ml/machine-learning-databases/00302/gesture_phase_dataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘gesture_phase_dataset.zip’\n",
            "\n",
            "gesture_phase_datas     [   <=>              ]   1.85M  3.49MB/s    in 0.5s    \n",
            "\n",
            "2025-02-19 12:07:55 (3.49 MB/s) - ‘gesture_phase_dataset.zip’ saved [1943494]\n",
            "\n",
            "Archive:  gesture_phase_dataset.zip\n",
            "  inflating: data/gesture/a1_va3.csv  \n",
            "  inflating: data/gesture/a2_raw.csv  \n",
            "  inflating: data/gesture/a2_va3.csv  \n",
            "  inflating: data/gesture/a3_raw.csv  \n",
            "  inflating: data/gesture/a3_va3.csv  \n",
            "  inflating: data/gesture/b1_raw.csv  \n",
            "  inflating: data/gesture/b1_va3.csv  \n",
            "  inflating: data/gesture/b3_raw.csv  \n",
            "  inflating: data/gesture/b3_va3.csv  \n",
            "  inflating: data/gesture/c1_raw.csv  \n",
            "  inflating: data/gesture/c1_va3.csv  \n",
            "  inflating: data/gesture/c3_raw.csv  \n",
            "  inflating: data/gesture/c3_va3.csv  \n",
            "  inflating: data/gesture/data_description.txt  \n",
            "  inflating: data/gesture/a1_raw.csv  \n",
            "--2025-02-19 12:07:55--  https://archive.ics.uci.edu/ml/machine-learning-databases/00357/occupancy_data.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘occupancy_data.zip’\n",
            "\n",
            "occupancy_data.zip      [  <=>               ] 327.84K  1.06MB/s    in 0.3s    \n",
            "\n",
            "2025-02-19 12:07:56 (1.06 MB/s) - ‘occupancy_data.zip’ saved [335713]\n",
            "\n",
            "Archive:  occupancy_data.zip\n",
            "  inflating: data/occupancy/datatest.txt  \n",
            "  inflating: data/occupancy/datatest2.txt  \n",
            "  inflating: data/occupancy/datatraining.txt  \n",
            "--2025-02-19 12:07:56--  https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘Metro_Interstate_Traffic_Volume.csv.gz’\n",
            "\n",
            "Metro_Interstate_Tr     [  <=>               ] 395.87K  1020KB/s    in 0.4s    \n",
            "\n",
            "2025-02-19 12:07:57 (1020 KB/s) - ‘Metro_Interstate_Traffic_Volume.csv.gz’ saved [405373]\n",
            "\n",
            "--2025-02-19 12:07:57--  https://archive.ics.uci.edu/ml/machine-learning-databases/ozone/eighthr.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘eighthr.data’\n",
            "\n",
            "eighthr.data            [  <=>               ] 799.15K  2.00MB/s    in 0.4s    \n",
            "\n",
            "2025-02-19 12:07:58 (2.00 MB/s) - ‘eighthr.data’ saved [818329]\n",
            "\n",
            "--2025-02-19 12:07:58--  https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘household_power_consumption.zip’\n",
            "\n",
            "household_power_con     [     <=>            ]  19.68M  22.2MB/s    in 0.9s    \n",
            "\n",
            "2025-02-19 12:07:59 (22.2 MB/s) - ‘household_power_consumption.zip’ saved [20640916]\n",
            "\n",
            "Archive:  household_power_consumption.zip\n",
            "  inflating: data/power/household_power_consumption.txt  \n",
            "--2025-02-19 12:08:00--  https://archive.ics.uci.edu/ml/machine-learning-databases/00196/ConfLongDemo_JSI.txt\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘ConfLongDemo_JSI.txt’\n",
            "\n",
            "ConfLongDemo_JSI.tx     [     <=>            ]  20.55M  22.7MB/s    in 0.9s    \n",
            "\n",
            "2025-02-19 12:08:01 (22.7 MB/s) - ‘ConfLongDemo_JSI.txt’ saved [21546346]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/py37_env/lib/python3.7/site-packages')"
      ],
      "metadata": {
        "id": "etPpojQ6HKI4"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!py37_env/bin/python3 -m pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbijDbi-ImHv",
        "outputId": "00588a94-ba31-4152-b2d1-41c39498ff71"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n",
            "  Using cached numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.1 kB)\n",
            "Using cached numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Installing collected packages: numpy\n",
            "Successfully installed numpy-1.21.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!py37_env/bin/python -m pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or6JaX-XIu_r",
        "outputId": "a4c4d8d4-d32a-447d-8cbf-4965a2ebf9ee"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas\n",
            "  Using cached pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting python-dateutil>=2.7.3 (from pandas)\n",
            "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2017.3 (from pandas)\n",
            "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in ./py37_env/lib/python3.7/site-packages (from pandas) (1.21.6)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.7.3->pandas)\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Using cached pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pytz, six, python-dateutil, pandas\n",
            "Successfully installed pandas-1.3.5 python-dateutil-2.9.0.post0 pytz-2025.1 six-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!py37_env/bin/python -m pip install tensorflow==1.14"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09EdRBxEIzhG",
        "outputId": "21fb2fa4-7626-41b6-8856-3a01c8159990"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==1.14\n",
            "  Using cached tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting absl-py>=0.7.0 (from tensorflow==1.14)\n",
            "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting astor>=0.6.0 (from tensorflow==1.14)\n",
            "  Using cached astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting gast>=0.2.0 (from tensorflow==1.14)\n",
            "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting google-pasta>=0.1.6 (from tensorflow==1.14)\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting keras-applications>=1.0.6 (from tensorflow==1.14)\n",
            "  Using cached Keras_Applications-1.0.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting keras-preprocessing>=1.0.5 (from tensorflow==1.14)\n",
            "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in ./py37_env/lib/python3.7/site-packages (from tensorflow==1.14) (1.21.6)\n",
            "Requirement already satisfied: six>=1.10.0 in ./py37_env/lib/python3.7/site-packages (from tensorflow==1.14) (1.17.0)\n",
            "Collecting protobuf>=3.6.1 (from tensorflow==1.14)\n",
            "  Using cached protobuf-4.24.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow==1.14)\n",
            "  Using cached tensorboard-1.14.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow==1.14)\n",
            "  Using cached tensorflow_estimator-1.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow==1.14)\n",
            "  Using cached termcolor-2.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting wrapt>=1.11.1 (from tensorflow==1.14)\n",
            "  Using cached wrapt-1.16.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting grpcio>=1.8.6 (from tensorflow==1.14)\n",
            "  Using cached grpcio-1.62.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: wheel>=0.26 in ./py37_env/lib/python3.7/site-packages (from tensorflow==1.14) (0.42.0)\n",
            "Collecting h5py (from keras-applications>=1.0.6->tensorflow==1.14)\n",
            "  Using cached h5py-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14)\n",
            "  Using cached Markdown-3.4.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in ./py37_env/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (68.0.0)\n",
            "Collecting werkzeug>=0.11.15 (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14)\n",
            "  Using cached Werkzeug-2.2.3-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting importlib-metadata>=4.4 (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14)\n",
            "  Using cached importlib_metadata-6.7.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=0.11.15->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14)\n",
            "  Using cached MarkupSafe-2.1.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting zipp>=0.5 (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14)\n",
            "  Using cached zipp-3.15.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting typing-extensions>=3.6.4 (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14)\n",
            "  Using cached typing_extensions-4.7.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Using cached tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Using cached grpcio-1.62.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
            "Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "Using cached protobuf-4.24.4-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\n",
            "Using cached tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "Using cached tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
            "Using cached wrapt-1.16.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "Using cached Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
            "Using cached Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
            "Using cached h5py-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "Using cached importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
            "Using cached MarkupSafe-2.1.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
            "Using cached zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
            "Installing collected packages: tensorflow-estimator, zipp, wrapt, typing-extensions, termcolor, protobuf, MarkupSafe, keras-preprocessing, h5py, grpcio, google-pasta, gast, astor, absl-py, werkzeug, keras-applications, importlib-metadata, markdown, tensorboard, tensorflow\n",
            "Successfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astor-0.8.1 gast-0.6.0 google-pasta-0.2.0 grpcio-1.62.3 h5py-3.8.0 importlib-metadata-6.7.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.4.4 protobuf-4.24.4 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-2.3.0 typing-extensions-4.7.1 werkzeug-2.2.3 wrapt-1.16.0 zipp-3.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!py37_env/bin/python3 -m pip install protobuf==3.19.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qit7D5OrJGpR",
        "outputId": "1fafaa65-5d21-4e41-ef08-825f8f18e88a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting protobuf==3.19.6\n",
            "  Using cached protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\n",
            "Using cached protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.24.4\n",
            "    Uninstalling protobuf-4.24.4:\n",
            "      Successfully uninstalled protobuf-4.24.4\n",
            "Successfully installed protobuf-3.19.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!py37_env/bin/python ozone.py --model ctgru --epoch 10 --log 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBPyP8ylpmyH",
        "outputId": "b34b2090-4274-4a52-e2a7-99723f6b32cb"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/liquid_time_constant_networks/experiments_with_ltcs/py37_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/content/liquid_time_constant_networks/experiments_with_ltcs/py37_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/content/liquid_time_constant_networks/experiments_with_ltcs/py37_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/content/liquid_time_constant_networks/experiments_with_ltcs/py37_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/content/liquid_time_constant_networks/experiments_with_ltcs/py37_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/content/liquid_time_constant_networks/experiments_with_ltcs/py37_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/content/liquid_time_constant_networks/experiments_with_ltcs/py37_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/content/liquid_time_constant_networks/experiments_with_ltcs/py37_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/content/liquid_time_constant_networks/experiments_with_ltcs/py37_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/content/liquid_time_constant_networks/experiments_with_ltcs/py37_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/content/liquid_time_constant_networks/experiments_with_ltcs/py37_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/content/liquid_time_constant_networks/experiments_with_ltcs/py37_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From /content/liquid_time_constant_networks/experiments_with_ltcs/ltc_model.py:17: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
            "\n",
            "Missing features in 687 out of 2535 samples (27.10)\n",
            "Read 2534 lines\n",
            "Imbalance: 6.31%\n",
            "Total number of training sequences: 32\n",
            "WARNING:tensorflow:From ozone.py:115: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From ozone.py:141: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /content/liquid_time_constant_networks/experiments_with_ltcs/ctrnn_model.py:240: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/liquid_time_constant_networks/experiments_with_ltcs/ctrnn_model.py:243: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/liquid_time_constant_networks/experiments_with_ltcs/py37_env/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1026ef361bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1026ef361bd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:From /content/liquid_time_constant_networks/experiments_with_ltcs/ctrnn_model.py:223: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1026ef3bed50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1026ef3bed50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "/content/liquid_time_constant_networks/experiments_with_ltcs/ctrnn_model.py:259: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  h_hat_next = ((1-ski)*h_hat + ski*qk)*np.exp(-1.0/self.ln_tau_table)\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1026f0560e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1026f0560e10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "logit shape:  (?, ?, 2)\n",
            "WARNING:tensorflow:From ozone.py:155: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/liquid_time_constant_networks/experiments_with_ltcs/py37_env/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "loss shape:  ()\n",
            "WARNING:tensorflow:From ozone.py:163: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From ozone.py:184: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n",
            "2025-02-19 14:10:35.784796: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2025-02-19 14:10:35.789812: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200225000 Hz\n",
            "2025-02-19 14:10:35.790074: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2ba49d0 executing computations on platform Host. Devices:\n",
            "2025-02-19 14:10:35.790111: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "WARNING:tensorflow:From ozone.py:185: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "2025-02-19 14:10:35.823203: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "WARNING:tensorflow:From ozone.py:198: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "valid prec: 0.00, recall: 0.00\n",
            "Epochs 000, train loss: 0.15, train acc: 0.00, valid loss: 0.15, valid acc: 0.00, test loss: 0.15, test acc: 0.00\n",
            "valid prec: 2.90, recall: 1.59\n",
            "Epochs 005, train loss: 0.14, train acc: 0.03, valid loss: 0.14, valid acc: 0.02, test loss: 0.14, test acc: 0.02\n",
            "WARNING:tensorflow:From /content/liquid_time_constant_networks/experiments_with_ltcs/py37_env/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Best epoch 005, train loss: 0.14, train acc: 0.02, valid loss: 0.14, valid acc: 0.02, test loss: 0.14, test acc: 0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "39h8kFNjqPSf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}